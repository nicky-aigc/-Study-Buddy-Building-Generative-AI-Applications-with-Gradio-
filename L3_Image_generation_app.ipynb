{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c635960",
   "metadata": {},
   "source": [
    "# L3: Image generation app ðŸŽ¨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c186d0",
   "metadata": {},
   "source": [
    "Load your HF API key and relevant Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0447fb8-b684-4835-9a31-1d0a824d2607",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import IPython.display\n",
    "from PIL import Image\n",
    "import base64 \n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "# run it locally\n",
    "hf_api_key = os.environ['HF_API_KEY']\n",
    "hf_inf_key = os.environ['HF_INF_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b3b590",
   "metadata": {},
   "source": [
    "# Run it using inference API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009d42b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "API_URL = \"https://api-inference.huggingface.co/models/runwayml/stable-diffusion-v1-5\"\n",
    "headers = {\"Authorization\": f\"Bearer {hf_inf_key}\"}\n",
    "\n",
    "payload = {\n",
    "    \"inputs\": \"a robot on Mars\",\n",
    "\t\"negative_prompt\": \"green grass\",\n",
    "\t\"num_inference_steps\": 25,\n",
    "\t\"guidance_scale\": 7,\n",
    "\t\"width\": 512,\n",
    "\t\"height\": 512\n",
    "}\n",
    "\n",
    "def query(payload):\n",
    "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
    "\treturn response.content\n",
    "image_bytes = query(payload)\n",
    "# You can access the image with PIL.Image for example\n",
    "image = Image.open(io.BytesIO(image_bytes))\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c058920b",
   "metadata": {},
   "source": [
    "# Run it locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1b5677-271a-46ac-a02e-656f2e315e15",
   "metadata": {
    "height": 317
   },
   "outputs": [],
   "source": [
    "# Helper function\n",
    "from diffusers import StableDiffusionPipeline\n",
    "import torch\n",
    "# this model also supports negative prompt steps guidance and width/height\n",
    "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16, use_safetensors=True).to(\"mps\")\n",
    "# Recommended if your computer has < 64 GB of RAM\n",
    "# pipe.enable_attention_slicing()\n",
    "prompt = \"a photo of an astronaut on Mars\"\n",
    "image = pipe(prompt).images[0]\n",
    "image.show()\n",
    "image.save(\"output.png\")    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764a85ed",
   "metadata": {},
   "source": [
    "## Building an image generation app "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05fab52",
   "metadata": {},
   "source": [
    "Here we are going to run `runwayml/stable-diffusion-v1-5` using the `ðŸ§¨ diffusers` library.\n",
    "\n",
    "We can us both IPython.display.HTML or Image.open to display the output image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28748bf-2618-4b8c-aa6f-7aad9c573af8",
   "metadata": {
    "height": 96
   },
   "outputs": [],
   "source": [
    "prompt = \"a basketball lying on the playground\"\n",
    "image = pipe(prompt).images[0]\n",
    "image.save(\"output.png\") \n",
    "\n",
    "\n",
    "\n",
    "# IPython.display.HTML(f'<img src=\"data:image/png;base64,{base64.b64encode(open(\"output.png\", \"rb\").read()).decode()}\" />')\n",
    "Image.open('output.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee90440",
   "metadata": {},
   "source": [
    "## Generating with `gr.Interface()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af05f0b8",
   "metadata": {},
   "source": [
    "### when the image is in the same directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136702a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt):\n",
    "    image = pipe(prompt).images[0]\n",
    "    image.save(\"output.png\") \n",
    "    return \"output.png\"\n",
    "\n",
    "\n",
    "get_completion(\"a man in a red shirt\")\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "gr.close_all()\n",
    "demo = gr.Interface(fn=get_completion,\n",
    "                    inputs=[gr.Textbox(label=\"Your prompt\")],\n",
    "                    outputs=[gr.Image(label=\"Result\", type=\"filepath\")],\n",
    "                    title=\"Image Generation with Stable Diffusion\",\n",
    "                    description=\"Generate any image with Stable Diffusion\",\n",
    "                    allow_flagging=\"never\",\n",
    "                    examples=[\"the spirit of a tamagotchi wandering in the city of Vienna\",\"a mecha robot in a favela\"])\n",
    "\n",
    "demo.launch()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ceb3a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58fc5e5",
   "metadata": {},
   "source": [
    "### When the image is in base64 format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024026ce-7832-4749-8992-50d31d61fcda",
   "metadata": {
    "height": 453
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "#A helper function to convert the PIL image to base64\n",
    "#so you can send it to the API\n",
    "import requests\n",
    "\n",
    "API_URL = \"https://api-inference.huggingface.co/models/runwayml/stable-diffusion-v1-5\"\n",
    "headers = {\"Authorization\": f\"Bearer {hf_inf_key}\"}\n",
    "\n",
    "def query(inputs):\n",
    "    payload = {\"inputs\": inputs}\n",
    "    response = requests.post(API_URL, headers=headers, json=payload)\n",
    "    image = Image.open(io.BytesIO(response.content))\n",
    "    image.save(\"output.jpg\")\n",
    "    img_base64 = base64.b64encode(open(\"output.jpg\", \"rb\").read()).decode('utf-8')\n",
    "    base64_decoded = base64.b64decode(img_base64)\n",
    "    byte_stream = io.BytesIO(base64_decoded)\n",
    "    pil_image = Image.open(byte_stream)\n",
    "    return pil_image\n",
    "\n",
    "\n",
    "\n",
    "gr.close_all()\n",
    "demo = gr.Interface(fn=query,\n",
    "                    inputs=[gr.Textbox(label=\"Your prompt\")],\n",
    "                    outputs=[gr.Image(label=\"Result\",type=\"pil\")],\n",
    "                    title=\"Image Generation with Stable Diffusion\",\n",
    "                    description=\"Generate any image with Stable Diffusion\",\n",
    "                    allow_flagging=\"never\",\n",
    "                    examples=[\"the spirit of a tamagotchi wandering in the city of Vienna\",\"a mecha robot in a favela\"])\n",
    "\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d16450",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "demo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7a7330",
   "metadata": {},
   "source": [
    "## Building a more advanced interface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a4b72f",
   "metadata": {},
   "source": [
    "### when the image is in the same directory.\n",
    "You can refer to below link to see how different parameters work in the pipeline.(so you can use those when running locally)   \n",
    "[pipeline doc](https://huggingface.co/docs/diffusers/v0.30.0/en/api/pipelines/stable_diffusion/text2img#diffusers.StableDiffusionPipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea60bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr \n",
    "\n",
    "# the \n",
    "def get_completion(prompt, negative_prompt, steps, guidance, width, height):\n",
    "\n",
    "    image = pipe(prompt=prompt,negative_prompt=negative_prompt, steps=steps, guidance=guidance, width=width, height=height).images[0]\n",
    "    image.save(\"output.png\") \n",
    "    return \"output.png\"\n",
    "\n",
    "\n",
    "gr.close_all()\n",
    "demo = gr.Interface(fn=get_completion,\n",
    "                    inputs=[\n",
    "                        gr.Textbox(label=\"Your prompt\"),\n",
    "                        gr.Textbox(label=\"Negative prompt\"),\n",
    "                        gr.Slider(label=\"Inference Steps\", minimum=1, maximum=100, value=25,\n",
    "                                 info=\"In how many steps will the denoiser denoise the image?\"),\n",
    "                        gr.Slider(label=\"Guidance Scale\", minimum=1, maximum=20, value=7, \n",
    "                                  info=\"Controls how much the text prompt influences the result\"),\n",
    "                        gr.Slider(label=\"Width\", minimum=64, maximum=512, step=64, value=512),\n",
    "                        gr.Slider(label=\"Height\", minimum=64, maximum=512, step=64, value=512),\n",
    "                    ],\n",
    "                    outputs=[gr.Image(label=\"Result\", type=\"filepath\")],\n",
    "                    # the example should have as many parameters as above\n",
    "                    examples=[[\"the spirit of a tamagotchi wandering in the city of Vienna\",\"countryside\",25,7,512,512],[\"a mecha robot in a favela\",\"human\",25,7,512,512]],\n",
    "                    title=\"Image Generation with Stable Diffusion\",\n",
    "                    description=\"Generate any image with Stable Diffusion\",\n",
    "                    allow_flagging=\"never\"\n",
    "                    )\n",
    "\n",
    "demo.launch(share=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38bedbb",
   "metadata": {},
   "source": [
    "### When the image is in base64 format.\n",
    "as the inference endpoint does not support other parameters other than inputs, so other parameters won't take effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2aec35-51e6-4f12-b096-189a968ef8e3",
   "metadata": {
    "height": 402
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "#A helper function to convert the PIL image to base64\n",
    "#so you can send it to the API\n",
    "import requests\n",
    "import json\n",
    "\n",
    "API_URL = \"https://api-inference.huggingface.co/models/runwayml/stable-diffusion-v1-5\"\n",
    "headers = {\"Authorization\": f\"Bearer {hf_inf_key}\"}\n",
    "\n",
    "def query(prompt, negative_prompt, steps, guidance, width, height):\n",
    "    payload = {\n",
    "        \"inputs\": prompt,\n",
    "        \"negative_prompt\": negative_prompt,\n",
    "        \"steps\": steps,\n",
    "        \"guidance\": guidance,\n",
    "        \"width\": width,\n",
    "        \"height\": height}\n",
    "    \n",
    "    json_string= json.dumps(payload)\n",
    "\n",
    "    \n",
    "    response = requests.post(API_URL, headers=headers, json=payload)\n",
    "    # print(response.content)\n",
    "    image = Image.open(io.BytesIO(response.content))\n",
    "    image.save(\"output.jpg\")\n",
    "    img_base64 = base64.b64encode(open(\"output.jpg\", \"rb\").read()).decode('utf-8')\n",
    "    base64_decoded = base64.b64decode(img_base64)\n",
    "    byte_stream = io.BytesIO(base64_decoded)\n",
    "    pil_image = Image.open(byte_stream)\n",
    "    return pil_image\n",
    "\n",
    "\n",
    "gr.close_all()\n",
    "demo = gr.Interface(fn=query,\n",
    "                    inputs=[\n",
    "                        gr.Textbox(label=\"Your prompt\"),\n",
    "                        gr.Textbox(label=\"Negative prompt\"),\n",
    "                        gr.Slider(label=\"Inference Steps\", minimum=1, maximum=100, value=25,\n",
    "                                 info=\"In how many steps will the denoiser denoise the image?\"),\n",
    "                        gr.Slider(label=\"Guidance Scale\", minimum=1, maximum=20, value=7, \n",
    "                                  info=\"Controls how much the text prompt influences the result\"),\n",
    "                        gr.Slider(label=\"Width\", minimum=64, maximum=512, step=64, value=512),\n",
    "                        gr.Slider(label=\"Height\", minimum=64, maximum=512, step=64, value=512),\n",
    "                    ],\n",
    "                    outputs=[gr.Image(label=\"Result\", type=\"filepath\")],\n",
    "                    title=\"Image Generation with Stable Diffusion\",\n",
    "                    description=\"Generate any image with Stable Diffusion\",\n",
    "                    allow_flagging=\"never\")\n",
    "\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48190bc3-6f1d-43ab-816c-e9b4eb65899d",
   "metadata": {},
   "source": [
    "#### gr.Slider()\n",
    "- You can set the `minimum`, `maximum`, and starting `value` for a `gr.Slider()`.\n",
    "- If you want the slider to increment by integer values, you can set `step=1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c844370-4c46-4115-858e-f5cd5fe337ab",
   "metadata": {
    "height": 351
   },
   "outputs": [],
   "source": [
    "gr.close_all()\n",
    "demo = gr.Interface(fn=get_completion,\n",
    "                    inputs=[\n",
    "                        gr.Textbox(label=\"Your prompt\"),\n",
    "                        gr.Textbox(label=\"Negative prompt\"),\n",
    "                        gr.Slider(label=\"Inference Steps\", minimum=1, maximum=100, value=25,\n",
    "                                 info=\"In how many steps will the denoiser denoise the image?\"),\n",
    "                        gr.Slider(label=\"Guidance Scale\", minimum=1, maximum=20, value=7, \n",
    "                                  info=\"Controls how much the text prompt influences the result\"),\n",
    "                        gr.Slider(label=\"Width\", minimum=64, maximum=512, step=64, value=512),\n",
    "                        gr.Slider(label=\"Height\", minimum=64, maximum=512, step=64, value=512),\n",
    "                    ],\n",
    "                    outputs=[gr.Image(label=\"Result\")],\n",
    "                    title=\"Image Generation with Stable Diffusion\",\n",
    "                    description=\"Generate any image with Stable Diffusion\",\n",
    "                    allow_flagging=\"never\"\n",
    "                    )\n",
    "\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71999364",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "demo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a95b525",
   "metadata": {},
   "source": [
    "## `gr.Blocks()`\n",
    "\n",
    "- Within `gr.Blocks()`, you can define multiple `gr.Row()`s, or multiple `gr.Column()`s.\n",
    "- Note that if the jupyter notebook is very narrow, the layout may change to better display the objects.  If you define two columns but don't see the two columns in the app, try expanding the width of your web browser, and the screen containing this jupyter notebook.\n",
    "\n",
    "- When using `gr.Blocks()`, you'll need to explicitly define the \"Submit\" button using `gr.Button()`, whereas the 'Clear' and 'Submit' buttons are automatically added when using `gr.Interface()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6818b5e-1342-439b-b129-a8904719d09c",
   "metadata": {
    "height": 351
   },
   "outputs": [],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# Image Generation with Stable Diffusion\")\n",
    "    prompt = gr.Textbox(label=\"Your prompt\")\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            negative_prompt = gr.Textbox(label=\"Negative prompt\")\n",
    "            steps = gr.Slider(label=\"Inference Steps\", minimum=1, maximum=100, value=25,\n",
    "                      info=\"In many steps will the denoiser denoise the image?\")\n",
    "            guidance = gr.Slider(label=\"Guidance Scale\", minimum=1, maximum=20, value=7,\n",
    "                      info=\"Controls how much the text prompt influences the result\")\n",
    "            width = gr.Slider(label=\"Width\", minimum=64, maximum=512, step=64, value=512)\n",
    "            height = gr.Slider(label=\"Height\", minimum=64, maximum=512, step=64, value=512)\n",
    "            btn = gr.Button(\"Submit\")\n",
    "        with gr.Column():\n",
    "            output = gr.Image(label=\"Result\")\n",
    "\n",
    "    btn.click(fn=get_completion, inputs=[prompt,negative_prompt,steps,guidance,width,height], outputs=[output])\n",
    "gr.close_all()\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f13197-6af1-4818-8122-63d52c41daae",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "demo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe6f7a8-8cd5-422e-a622-f9aef30fadb3",
   "metadata": {},
   "source": [
    "#### scale\n",
    "\n",
    "- To choose how much relative width to give to each column, set the `scale` parameter of each `gr.Column()`.  \n",
    "- If one column has `scale=4` and the second column has `scale=1`, then the first column takes up 4/5 of the total width, and the second column takes up 1/5 of the total width.\n",
    "\n",
    "#### gr.Accordion()\n",
    "- The `gr.Accordion()` can show/hide  the app options with a mouse click.\n",
    "- Set `open=True` to show the contents of the Accordion by default, or `False` to hide it by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655908ab-fa08-4b86-b218-f685f62d3638",
   "metadata": {
    "height": 436
   },
   "outputs": [],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# Image Generation with Stable Diffusion\")\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=4):\n",
    "            prompt = gr.Textbox(label=\"Your prompt\") #Give prompt some real estate\n",
    "        with gr.Column(scale=1, min_width=50):\n",
    "            btn = gr.Button(\"Submit\") #Submit button side by side!\n",
    "    with gr.Accordion(\"Advanced options\", open=False): #Let's hide the advanced options!\n",
    "            negative_prompt = gr.Textbox(label=\"Negative prompt\")\n",
    "            with gr.Row():\n",
    "                with gr.Column():\n",
    "                    steps = gr.Slider(label=\"Inference Steps\", minimum=1, maximum=100, value=25,\n",
    "                      info=\"In many steps will the denoiser denoise the image?\")\n",
    "                    guidance = gr.Slider(label=\"Guidance Scale\", minimum=1, maximum=20, value=7,\n",
    "                      info=\"Controls how much the text prompt influences the result\")\n",
    "                with gr.Column():\n",
    "                    width = gr.Slider(label=\"Width\", minimum=64, maximum=512, step=64, value=512)\n",
    "                    height = gr.Slider(label=\"Height\", minimum=64, maximum=512, step=64, value=512)\n",
    "    output = gr.Image(label=\"Result\") #Move the output up too\n",
    "            \n",
    "    btn.click(fn=get_completion, inputs=[prompt,negative_prompt,steps,guidance,width,height], outputs=[output])\n",
    "\n",
    "gr.close_all()\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91ece7c-f5a5-4025-8558-23bd2e007ed2",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "gr.close_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30d2cbd-a799-40dc-9c50-a3e26080a16b",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
